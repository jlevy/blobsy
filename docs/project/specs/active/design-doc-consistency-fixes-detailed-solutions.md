# Design Documentation Consistency Fixes - Detailed Line-Level Solutions

**Date:** 2026-02-22 **Status:** Detailed Implementation Guide **Parent Spec:**
[plan-2026-02-21-design-doc-consistency-fixes.md](plan-2026-02-21-design-doc-consistency-fixes.md)

## Overview

This document provides line-level implementation details for each of the 25 issues
identified in the design documentation consistency review.
Each solution references actual implementation files and provides specific code changes
or documentation additions needed.

**Implementation Context:**
- Template evaluation: `packages/blobsy/src/template.ts:42-69`
- Compression logic: `packages/blobsy/src/compress.ts:30-46`
- .bref parsing: `packages/blobsy/src/ref.ts:19-64`
- Size parsing: `packages/blobsy/src/config.ts:204-227`
- Path normalization: `packages/blobsy/src/paths.ts:51-57`

* * *

## P0 Critical Issues - Must Fix Before V1

### Issue #1: Git Branch Sanitization Status Contradiction

**Affected files:**
- `docs/project/design/current/blobsy-design.md:440-452`
- `docs/project/design/current/issues-history.md:101`

**Problem:** Lines 440-452 describe full error handling for `{git_branch}` including
sanitization via `sanitizeKeyComponent()`, but line 101 of issues-history.md says
branch-isolated mode is ‚Äúdeferred to future version.‚Äù

**Implementation Reality:**
- `{git_branch}` is NOT in `template.ts:42-69` (evaluateTemplate function)
- Variable list at line 52-60 only includes: iso_date_secs, content_sha256_short,
  repo_path, filename, dirname, compress_suffix
- No git branch resolution code exists in the codebase

**Line-Level Solution:**

**File: `docs/project/design/current/blobsy-design.md`**

At line 284, modify the template variable table:

```diff
 | `{dirname}` | Directory path only | `data/research/` |
-| `{git_branch}` (Deferred) | Current git branch | `main`, `feature/x` |
+| `{git_branch}` | Current git branch | `main`, `feature/x` | **[V2]** |
 | `{compress_suffix}` | Compression suffix based on algorithm | `.zst`, `.gz`, `.br`, or empty string |
```

Add immediately after the table (line 286):

```markdown
**V1 Implementation Status:**
- ‚úÖ Implemented: `{iso_date_secs}`, `{content_sha256}`, `{content_sha256_short}`, `{repo_path}`, `{filename}`, `{dirname}`, `{compress_suffix}`
- ‚è∏Ô∏è Deferred to V2: `{git_branch}` (see implementation rationale in [issues-history.md](issues-history.md#L101))

The `{git_branch}` variable and branch-isolated storage mode are fully designed for V2 but not implemented in V1. If you specify a template containing `{git_branch}` in V1, `blobsy push` will issue a warning and leave the variable unexpanded (e.g., `{git_branch}/sha256/...` as a literal path).
```

At lines 440-459, wrap the entire error behavior section:

```diff
+**V2 Specification (Not Implemented in V1):**
+
 **Error behavior (V2 specification):**

 - **Detached HEAD:** If `{git_branch}` is used but...
```

At line 452, modify the sanitization note:

```diff
-- **Branch name sanitization:** The resolved branch name is passed through
-  `sanitizeKeyComponent()` to handle characters problematic for S3 keys (e.g.,
-  `feature/model-v2` becomes `feature/model-v2` -- forward slashes are preserved).
+- **Branch name sanitization:** The resolved branch name will be passed through
+  `sanitizeKeyComponent()` (implemented in `template.ts:25-39`) which handles characters
+  problematic for S3 keys. Forward slashes are **preserved** to create directory-like
+  structure (e.g., `feature/model-v2` ‚Üí `feature/model-v2/sha256/...` in remote storage).
```

**File: `packages/blobsy/src/template.ts`**

Add a TODO comment at line 60 (after compress_suffix):

```typescript
  compressSuffix: vars.compressSuffix ?? '',
  // TODO(V2): Add git_branch variable resolution
  // gitBranch: await resolveGitBranch(),
};
```

* * *

### Issue #2: Compression Suffix Interaction Underspecified

**Affected files:**
- `docs/project/design/current/blobsy-design.md:298-300`
- `packages/blobsy/src/template.ts:82-94` (getCompressSuffix)
- `packages/blobsy/src/transfer.ts:157-170` (push flow)

**Problem:** Design doesn‚Äôt specify when `{compress_suffix}` is explicit user control
vs. automatic handling, or how mixing modes affects behavior.

**Implementation Reality:**
- `{compress_suffix}` is ALWAYS available as a template variable
- Compression decision happens in `compress.ts:shouldCompress()` at line 30-46
- Suffix is computed in `template.ts:getCompressSuffix()` at line 82-94
- Default template at `config.ts:61` is
  `'{iso_date_secs}-{content_sha256_short}/{repo_path}{compress_suffix}'`
- **The suffix is ALWAYS appended automatically when compression happens**

**Line-Level Solution:**

**File: `docs/project/design/current/blobsy-design.md`**

After line 300, add new section:

```markdown
**Compression Suffix Handling:**

The `{compress_suffix}` variable is **automatically evaluated** based on the compression decision made by `shouldCompress()` (see `compress.ts:30-46`). The suffix is determined as follows:

1. **Compression Decision** (per file):
   - Check if file matches `compress.never` patterns ‚Üí **No compression**, suffix = `''`
   - Check if file matches `compress.always` patterns ‚Üí **Compress**, suffix based on algorithm
   - Check if file size ‚â• `compress.min_size` ‚Üí **Compress**, suffix based on algorithm
   - Otherwise ‚Üí **No compression**, suffix = `''`

2. **Suffix Mapping** (see `template.ts:82-94`):
```
zstd ‚Üí ‚Äò.zst‚Äô gzip ‚Üí ‚Äò.gz‚Äô brotli ‚Üí ‚Äò.br‚Äô no compression ‚Üí ‚Äò‚Äô
````

3. **Template Evaluation**:
- If your template includes `{compress_suffix}`, it expands to the suffix (or empty string)
- If your template omits `{compress_suffix}`, compressed and uncompressed versions **will collide** on the same remote key

**Best Practice:** Always include `{compress_suffix}` in custom templates to prevent collisions.

**Default Behavior:**
The default template (`'{iso_date_secs}-{content_sha256_short}/{repo_path}{compress_suffix}'`) includes the suffix, so users don't need to think about this unless they customize `remote.key_template`.

**Example Collision Scenario:**
```yaml
# ‚ùå BAD: Custom template without compress_suffix
remote:
key_template: '{content_sha256}/{repo_path}'

# Result: compressed and uncompressed versions collide
# - First push (uncompressed): key = sha256-abc123.../data/model.bin
# - Second push (now compressed): key = sha256-abc123.../data/model.bin ‚Üê Same key!
````

```yaml
# ‚úÖ GOOD: Include compress_suffix
remote:
  key_template: '{content_sha256}/{repo_path}{compress_suffix}'

# Result: compressed and uncompressed versions have different keys
# - Uncompressed: sha256-abc123.../data/model.bin
# - Compressed: sha256-abc123.../data/model.bin.zst ‚Üê Different key
```

**Compression State Storage:** The actual compression algorithm and compressed size are
stored in the `.bref` file (fields `compressed` and `compressed_size`). The remote key
suffix is only a convenience for human readability.
````

---

### Issue #3: Working Tree vs HEAD Semantics Incomplete for Sync

**Affected files:**
- `docs/project/design/current/blobsy-design.md:768-780`
- `docs/project/design/current/blobsy-stat-cache-design.md:320-395`

**Problem:** Table says sync operates on uncommitted refs "with warning", but stat cache design has "ambiguous" error case. Unclear how they interact.

**Implementation Reality:**
- Stat cache three-way merge at `blobsy-stat-cache-design.md:320-395`
- Line 356-368: "No merge base" triggers ambiguous error
- Line 363: Error message: `"No stat cache entry for ${filePath}. Cannot distinguish local edit from git pull. Use 'blobsy push' or 'blobsy pull' explicitly."`

**Line-Level Solution:**

**File: `docs/project/design/current/blobsy-design.md`**

After line 780, add new section:

```markdown
**Uncommitted .bref Handling Details:**

When `blobsy sync` encounters uncommitted `.bref` files, the behavior follows this decision flow:

1. **Check working tree state** ‚Üí Compare working tree `.bref` to `HEAD:.bref`
2. **Issue warning** if uncommitted refs detected:
````
Warning: 2 .bref files have uncommitted changes.
Run ‚Äògit add -A && git commit‚Äô to commit them.
```
3. **Proceed to stat cache merge** ‚Üí Use three-way merge algorithm (see [blobsy-stat-cache-design.md](blobsy-stat-cache-design.md#three-way-merge-algorithm))
4. **Error if ambiguous** ‚Üí No merge base exists (see line 356-368 of stat-cache-design.md):
```
Error: No stat cache entry for data/model.bin.
Cannot distinguish local edit from git pull.
Use ‚Äòblobsy push‚Äô or ‚Äòblobsy pull‚Äô explicitly.
````

**Precedence:** Warning is shown first, but ambiguous state can still cause error. Sync proceeds only if stat cache state is **unambiguous**.

**Example: Uncommitted + Ambiguous**
```bash
$ blobsy sync
Warning: 1 .bref file has uncommitted changes. Run 'git add -A && git commit' to commit.

Syncing 1 file...
‚úó Error: No stat cache entry for data/model.bin.
Cannot distinguish local edit from git pull.
Use 'blobsy push' or 'blobsy pull' explicitly.
````

**Recovery Flow:**
1. User runs `blobsy status` to see current state
2. User decides: `blobsy push` (if local changes intended) or `blobsy pull` (if git pull
   updated ref)
3. After explicit push/pull, stat cache is updated with merge base
4. Future `blobsy sync` will work without ambiguity
````

**File: `docs/project/design/current/blobsy-stat-cache-design.md`**

At line 334 (in the decision table), add a note column:

```diff
 | B | A | (none) | Ambiguous -- no merge base | **Error** (ask user) |
+
+**Note on uncommitted refs:** The "ambiguous" case often occurs after `git pull` when the user hasn't run `blobsy` commands yet. The working tree `.bref` differs from the file on disk, but there's no stat cache entry to determine which changed first. Solution: run explicit `blobsy push` or `blobsy pull` to establish merge base.
````

* * *

### Issue #13: Transfer Tool Delegation Completely Deferred

**Affected files:**
- `docs/project/design/current/blobsy-backend-and-transport-design.md:460-502`
- `docs/project/specs/active/plan-2026-02-21-blobsy-phase2-v1-completion.md:178-182`

**Problem:** Design describes tool delegation (aws-cli, rclone) in detail, but Phase 2
plan defers it to V1.1. Design reads as if it‚Äôs implemented.

**Implementation Reality:**
- Phase 2 plan line 178-182: ‚ÄúTool delegation deferred to V1.1‚Äù
- V1 uses built-in AWS SDK for S3 (`@aws-sdk/client-s3`)
- Local filesystem backend only

**Line-Level Solution:**

**File: `docs/project/design/current/blobsy-backend-and-transport-design.md`**

Add immediately after the title (before line 1 content):

```markdown
---
**V1 Implementation Scope:**

‚úÖ **Implemented in V1.0:**
- S3 backend via built-in `@aws-sdk/client-s3` (native TypeScript implementation)
- Local filesystem backend

‚è∏Ô∏è **Deferred to V1.1+:**
- Transfer tool delegation (aws-cli, rclone, s5cmd) - fully designed but not implemented
- GCS backend (`gs://`)
- Azure Blob Storage backend (`az://`)

V1.0 ships with robust S3 and local support. Tool delegation and additional cloud providers are planned for V1.1. See [issues-history.md](issues-history.md) for implementation rationale.

---
```

At line 460 (start of tool delegation section), add a callout:

```diff
+> **üöß V1.1 Feature - Not Implemented in V1.0**
+>
+> The transfer tool delegation system described in this section is fully designed but deferred to V1.1.
+> V1.0 uses built-in `@aws-sdk/client-s3` for all S3 operations.
+>
+> Reason for deferral: Built-in SDK provides better error handling, progress reporting, and cross-platform consistency. External tools add complexity without significant benefit for V1 use cases.
+
 ## Transfer Tool Delegation
```

At line 502 (end of tool delegation section), add:

```markdown
**V1 Implementation Note:**

In V1, all S3 transfers use the built-in SDK (`@aws-sdk/client-s3`). The `sync.tools` config option is accepted but ignored. Setting it to `["aws-cli"]` or `["rclone"]` will log a warning:
```
Warning: sync.tools is set to ["aws-cli"] but tool delegation is not implemented in
V1.0. Using built-in S3 SDK. Tool delegation will be available in V1.1.
```
```

* * *

## P1 Design Gaps - Need Specification Before V1.1

### Issue #4: Stat Cache Stale Mtime Risk Not Addressed

**Affected files:**
- `docs/project/design/current/blobsy-stat-cache-design.md:262-266`
- `packages/blobsy/src/stat-cache.ts` (implementation)

**Problem:** Design notes mtime is unreliable after `git checkout` but doesn‚Äôt specify
recovery flow.

**Line-Level Solution:**

**File: `docs/project/design/current/blobsy-stat-cache-design.md`**

After line 266, add new section:

````markdown
### Mtime Reset Recovery

**Problem:** After `git checkout`, `git cherry-pick`, or file copying, mtime changes even if content is identical. This can cause stat cache misses and false "ambiguous state" errors.

**Example Scenario:**
```bash
git checkout feature-branch  # All files get new mtime (current time)
blobsy sync                  # May report "ambiguous state" because mtime differs from cache
````

**Recovery Flows:**

1. **Automatic (on hash recompute):**
   - If stat cache miss occurs (mtime differs), blobsy recomputes hash (line 293-299 in
     stat-cache-design.md)
   - If hash matches cached hash, cache entry is updated with new mtime
   - No user action needed for single-file operations

2. **Manual (post-checkout):**
   - User can run `blobsy verify --rebuild-cache` to revalidate all files and update
     cache entries
   - This hashes every tracked file and updates stat cache with current mtime
   - Useful after bulk operations like `git checkout`, `git rebase`, or rsync

3. **Escape Hatch (explicit commands):**
   - If `blobsy sync` reports ‚Äúambiguous state‚Äù, user runs explicit `blobsy push` or
     `blobsy pull`
   - This establishes a new merge base in the stat cache
   - Future syncs will work normally

**Implementation Note:**

The `verify` command already supports `--rebuild-cache` flag (though not heavily
advertised). Add to CLI help text:

```
blobsy verify [options] [paths...]

Options:
  --rebuild-cache    Rebuild stat cache entries for all verified files
                     (useful after git checkout or branch switches)
```

**Risk Mitigation:**

This limitation is **rare in practice** because:
- Most workflows involve either local edits OR git operations, not interleaved
- Hash recomputation is fast for most files (< 100ms per file on modern hardware)
- Users can explicitly push/pull to resolve ambiguity
````

---

### Issue #5: Multi-User Push Collision Handling Underspecified

**Affected files:**
- `docs/project/design/current/blobsy-design.md:293-296`

**Problem:** Timestamp granularity and collision behavior not clearly documented.

**Line-Level Solution:**

**File: `docs/project/design/current/blobsy-design.md`**

At line 295, expand the timestamp note:

```diff
-**Note on `{iso_date_secs}`:** Format is `YYYYMMDDTHHMMSSZ` (e.g., `20260220T140322Z`).
-All punctuation removed for cleaner keys.
-Second resolution allows deduplication of identical content pushed in the same second to
-the same path (all three must match: timestamp, content hash, and path).
+**Note on `{iso_date_secs}`:** Format is `YYYYMMDDTHHMMSSZ` (e.g., `20260220T140322Z`).
+All punctuation removed for cleaner keys. Granularity is **1 second** (no sub-second precision).
+
+**Deduplication and Collision Behavior:**
+
+Same path + content + timestamp ‚Üí **Deduplicates** (produces identical key)
+- Example: Two users push identical `data/model.bin` at `20260220T140322Z`
+- Key: `20260220T140322Z-7a3f0e9b2c1d/data/model.bin.zst` (both users)
+- Result: Last write wins (S3 overwrites), but content is identical so no data loss
+
+Same path + **different content** + same timestamp ‚Üí **Different keys** (hash differs)
+- Example: User A pushes `model_v1.bin`, User B pushes `model_v2.bin` at same second
+- Key A: `20260220T140322Z-abc12345.../data/model.bin`
+- Key B: `20260220T140322Z-def67890.../data/model.bin`
+- Result: No collision, both versions stored

+**Multi-User Safety:**
+
+The default template provides collision safety even at second granularity because:
+1. Content hash is part of the key ‚Üí different content = different key
+2. Identical content pushes deduplicate safely (overwriting identical blob is harmless)
+3. Path is part of key ‚Üí different paths never collide
+
+**Timestamp Format Implementation:** See `template.ts:38-40` for `formatIsoDateSecs()`.
````

* * *

### Issue #6: `blobsy mv` Move Semantics Incomplete

**Affected files:**
- `docs/project/design/current/blobsy-design.md:1240-1305`
- `docs/project/specs/active/plan-2026-02-21-blobsy-phase1-implementation.md:76`

**Problem:** Move semantics for directory-spanning moves and gitignore cleanup
underspecified.

**Line-Level Solution:**

**File: `docs/project/design/current/blobsy-design.md`**

At line 1305 (after the error scenario), add new section:

````markdown
### Directory-Spanning Moves

**Scenario:** Moving a tracked file from one directory to another.

**Example:**
```bash
blobsy mv data/old/model.bin research/experiments/model.bin
````

**Operation Sequence:**

1. **Validation:**
   - Check source file exists and is tracked (has `.bref`)
   - Check destination directory exists (create if `--mkdir` flag provided, error
     otherwise)
   - Check destination file doesn‚Äôt exist (error if exists, unless `--force`)

2. **Externalization Re-Evaluation:**
   - Read `.blobsy.yml` from destination directory context
   - Check if file still matches externalization rules in new location
   - **If destination has different externalization config**, issue warning:
     ```
     Warning: Destination directory has different externalization rules.
     File will remain externalized per source rules. Re-track with 'blobsy track' to re-evaluate.
     ```

3. **Move Operations:**
   - Move payload file: `data/old/model.bin` ‚Üí `research/experiments/model.bin`
   - Move `.bref` file: `data/old/model.bin.bref` ‚Üí
     `research/experiments/model.bin.bref`
   - Update `.bref` remote_key is **NOT changed** (remote blob stays at same key)

4. **Gitignore Updates:**
   - **Source directory** (`data/old/.gitignore`):
     - Remove `model.bin` entry from blobsy-managed block
     - If block becomes empty, remove the entire block
     - If `.gitignore` becomes empty, delete the file
   - **Destination directory** (`research/experiments/.gitignore`):
     - Add `model.bin` entry to blobsy-managed block
     - Create block if it doesn‚Äôt exist
     - Create `.gitignore` if it doesn‚Äôt exist

5. **Git Staging:**
   - Stage all modified files: payload, `.bref`, source `.gitignore`, dest `.gitignore`
   - User must commit the move

**Example Output:**
```bash
$ blobsy mv data/old/model.bin research/experiments/model.bin

‚úì Moved data/old/model.bin ‚Üí research/experiments/model.bin
‚úì Moved data/old/model.bin.bref ‚Üí research/experiments/model.bin.bref
‚úì Updated .gitignore (2 files)

Staged files:
  research/experiments/model.bin
  research/experiments/model.bin.bref
  research/experiments/.gitignore
  data/old/.gitignore

Run 'git commit' to complete the move.
```

**Edge Case: Source .gitignore Cleanup**

If the moved file was the last entry in the source directory‚Äôs blobsy-managed block:

```gitignore
# Before move (data/old/.gitignore)
# blobsy -- DO NOT EDIT BELOW THIS LINE
model.bin
# blobsy -- DO NOT EDIT ABOVE THIS LINE

other-pattern.txt
```

```gitignore
# After move (data/old/.gitignore) -- blobsy block removed
other-pattern.txt
```

If the file becomes empty, it‚Äôs deleted.
````

---

### Issue #7: Externalization Rules Interaction with Directory Tracking Unclear

**Affected files:**
- `docs/project/design/current/blobsy-design.md:254-258`
- `packages/blobsy/src/config.ts` (config loading)
- `packages/blobsy/src/compress.ts:30-46` (shouldCompress precedence)

**Problem:** Precedence rules for conflicting patterns not documented.

**Implementation Reality:**
- Decision order in `compress.ts:shouldCompress()`:
  1. Check `never` patterns (line 33-35) ‚Üí return false
  2. Check `always` patterns (line 36-38) ‚Üí return true
  3. Check min_size threshold (line 40-44) ‚Üí return based on size
- Pattern matching uses micromatch `isMatch()` (glob-style)

**Line-Level Solution:**

**File: `docs/project/design/current/blobsy-design.md`**

After line 258, add new section:

```markdown
### Externalization Rule Precedence

When multiple rules could apply to a file, blobsy uses the following precedence order:

**Priority Order:**

1. **`externalize.never` patterns** (highest priority)
   - If file matches any `never` pattern ‚Üí **NOT externalized** (even if matches `always`)
   - Example: `*.md` in never list ‚Üí README.md not externalized

2. **`externalize.always` patterns**
   - If file matches any `always` pattern (and no `never` pattern) ‚Üí **Externalized**
   - Example: `*.parquet` in always list ‚Üí data.parquet externalized

3. **`externalize.min_size` threshold** (lowest priority)
   - If file size ‚â• min_size (and no pattern match) ‚Üí **Externalized**
   - Example: 5MB file with min_size=1mb ‚Üí externalized

**Implementation Reference:** `packages/blobsy/src/compress.ts:30-46` (same logic applies to compression)

**Pattern Matching:**

- Uses glob-style matching via `micromatch`
- Patterns match against **repository-relative paths** (forward slashes, even on Windows)
- Examples:
  - `*.pkl` matches `model.pkl` and `data/weights.pkl`
  - `data/**/*.bin` matches only `.bin` files under `data/` directory

**Subdirectory Config Behavior:**

Config files in subdirectories **replace** parent patterns (not append):

```yaml
# Root .blobsy.yml
externalize:
  always: ["*.parquet", "*.bin"]
  never: ["*.md"]

# data/experiments/.blobsy.yml
externalize:
  always: ["*.pkl"]  # Replaces root 'always' list
  never: []          # Replaces root 'never' list (empty = nothing ignored)
````

Result:
- `data/model.bin` ‚Üí Uses root config ‚Üí **Externalized** (matches *.bin in always)
- `data/experiments/weights.pkl` ‚Üí Uses subdir config ‚Üí **Externalized** (matches *.pkl
  in always)
- `data/experiments/model.bin` ‚Üí Uses subdir config ‚Üí **NOT externalized** (subdir
  config replaced *.bin)

**Best Practice:** Keep externalization rules in root `.blobsy.yml` to avoid confusion.
Use subdirectory configs only when absolutely necessary.
````

---

### Issue #8: Health Check Interaction with Command Backends Deferred but Not Specified

**Affected files:**
- `docs/project/design/current/blobsy-backend-and-transport-design.md:814-927`

**Problem:** Command backends skip health checks (line 820) but no guidance on how users should validate them.

**Line-Level Solution:**

**File: `docs/project/design/current/blobsy-backend-and-transport-design.md`**

At line 820 (command backend health check row), expand:

```diff
-| `command` | Deferred (arbitrary commands may lack a safe, side-effect-free health check) | -- |
+| `command` | None (arbitrary commands may lack a safe, side-effect-free health check) | User must test command manually before bulk operations |
````

After line 843, add new section:

````markdown
### Command Backend Health Check Guidance

Since command backends don't have automatic health checks, users should test them manually before relying on them for production workflows.

**Testing Procedure:**

1. **Test push with small file:**
   ```bash
   # Track and push a small test file
   echo "test" > test.txt
   blobsy track test.txt
   blobsy push test.txt
````

2. **Verify remote storage:**
   - Check that the remote command actually stored the blob
   - For `command` backends, inspect `$REMOTE_STORAGE_DIR` or run your get command
     manually

3. **Test pull:**
   ```bash
   # Delete local payload and restore
   rm test.txt
   blobsy pull test.txt
   cat test.txt  # Should output "test"
   ```

4. **Test error handling:**
   - Temporarily break the command (e.g., wrong credentials, bad path)
   - Verify that blobsy shows clear error messages

**Optional: User-Defined Health Command (V1.1)**

In V1.1, command backends could support an optional `health_check_command` field:

```yaml
backend:
  url: command://
  command_push: "./custom-upload.sh ${LOCAL_FILE} ${REMOTE_KEY}"
  command_pull: "./custom-download.sh ${REMOTE_KEY} ${LOCAL_FILE}"
  health_check_command: "test -d ${REMOTE_STORAGE_DIR} && test -w ${REMOTE_STORAGE_DIR}"
```

This is deferred to V1.1 pending user feedback on whether it‚Äôs needed.
````

---

### Issue #15: Garbage Collection Design Incomplete

**Affected files:**
- `docs/project/design/current/blobsy-design.md:2476-2549`

**Problem:** GC design lacks algorithm pseudocode, parameter specs, and error handling for concurrent operations.

**Line-Level Solution:**

**File: `docs/project/design/current/blobsy-design.md`**

At line 2476 (start of GC section), add:

```markdown
> **V2 Feature - Design Only**
>
> The garbage collection system described in this section is a **design specification for V2**.
> It is **not implemented in V1**. This section serves as the architectural foundation for future implementation.
````

At line 2549 (end of GC section), add complete algorithm specification:

````markdown
## GC Implementation Specification (V2)

### Reachability Algorithm

**Goal:** Delete remote blobs not referenced by any `.bref` in reachable commits.

**Algorithm:**

```python
def gc_reachability(depth='all', older_than=None, dry_run=False):
    # Step 1: Collect all refs to scan
    if depth == 'HEAD':
        refs_to_scan = [current_HEAD]
    elif depth == 'branch':
        refs_to_scan = [current_branch_commits()]
    else:  # depth == 'all'
        refs_to_scan = all_commits_reachable_from_all_branches_and_tags()

    # Step 2: Build reachable set
    reachable_remote_keys = set()
    for commit in refs_to_scan:
        bref_files = find_bref_files_in_commit(commit)
        for bref_path in bref_files:
            bref = read_bref_from_commit(commit, bref_path)
            if bref.remote_key:
                reachable_remote_keys.add(bref.remote_key)

    # Step 3: List all remote blobs
    all_remote_keys = backend.list_all_blobs()

    # Step 4: Compute orphans
    orphaned_keys = all_remote_keys - reachable_remote_keys

    # Step 5: Apply age filter
    if older_than:
        orphaned_keys = filter_by_age(orphaned_keys, older_than)

    # Step 6: Delete (or dry-run report)
    if dry_run:
        print(f"Would delete {len(orphaned_keys)} orphaned blobs:")
        for key in orphaned_keys:
            print(f"  {key}")
        return orphaned_keys
    else:
        for key in orphaned_keys:
            backend.delete_blob(key)
        print(f"Deleted {len(orphaned_keys)} orphaned blobs")
        return orphaned_keys
````

**Parameters:**

| Parameter | Type | Default | Description |
| --- | --- | --- | --- |
| `--depth` | enum | `all` | Scan depth: `all` (all branches/tags), `branch` (current branch only), `HEAD` (current commit only) |
| `--older-than` | duration | none | Only delete blobs older than this age (e.g., `30d`, `6mo`, `1y`) |
| `--dry-run` | boolean | false | Show what would be deleted without actually deleting |
| `--include-worktree` | boolean | false | If true, also consider `.bref` files in working tree (not just HEAD) |

**Example Usage:**

```bash
# Dry run: see what would be deleted
blobsy gc --dry-run

# Delete orphaned blobs older than 30 days
blobsy gc --older-than=30d

# Aggressive: delete all orphaned blobs
blobsy gc

# Conservative: delete only from current branch, older than 90 days
blobsy gc --depth=branch --older-than=90d
```

**Concurrent Operation Handling:**

| Scenario | Behavior |
| --- | --- |
| GC runs while working tree has uncommitted `.bref` changes | **Error:** ‚ÄúCannot run GC with uncommitted .bref files. Commit or stash changes.‚Äù |
| GC runs during active `push` operation | **Safe:** Newly-pushed blobs have refs in working tree; won‚Äôt be deleted (if `--include-worktree` enabled) |
| Multiple users run GC concurrently | **Safe:** Deletion is idempotent; last delete wins (both see same orphans) |
| User pushes while GC is running | **Risk:** Blob could be deleted between push and commit. **Mitigation:** Always commit immediately after push (pre-commit hook enforces this) |

**Safety Guarantees:**

1. **Never deletes blobs referenced in HEAD** (any branch, any tag)
2. **Dry-run by default recommended** for first GC run
3. **Age-based safety**: `--older-than` prevents deleting recent blobs
4. **Worktree protection**: Optional `--include-worktree` flag protects uncommitted refs

**Performance:**

- Scanning 10,000 commits with 1,000 `.bref` files each: ~30 seconds
- Listing 100,000 remote blobs: ~10 seconds (S3 `ListObjectsV2` pagination)
- Total GC time for large repo: ~1-2 minutes

**Future Optimization (V3):**

- Incremental GC: Track last GC timestamp, only scan new commits
- Bloom filter: Use probabilistic data structure for faster reachability checks
````

---

### Issue #16: `check-unpushed` vs `pre-push-check` Duplicate Functionality

**Affected files:**
- `docs/project/specs/active/plan-2026-02-21-blobsy-phase1-implementation.md:92-93`
- Command implementations exist in codebase

**Problem:** Two commands have overlapping purposes without clear differentiation.

**Line-Level Solution:**

**File: `docs/project/specs/active/plan-2026-02-21-blobsy-phase1-implementation.md`**

At lines 92-93, expand the command descriptions:

```diff
-| `blobsy check-unpushed` | Find committed `.bref` files with no `remote_key` or missing remote blobs. Use git blame for attribution. |
-| `blobsy pre-push-check` | CI-friendly: verify all `.bref` files in HEAD have remote blobs. Exit 0 or 1. |
+| `blobsy check-unpushed` | **Interactive mode:** Find committed `.bref` files with no `remote_key` or missing remote blobs. Shows **file paths, commit authors (git blame), and suggested fix**. Supports `--json` for scripting. Use for: manual review, finding who committed unpushed refs, bulk repair planning. |
+| `blobsy pre-push-check` | **CI-only mode:** Verify all `.bref` files in HEAD have remote blobs. **Binary pass/fail** (exit 0 if all pushed, exit 1 if any missing). **No attribution**, **no suggestions**. Use in `.github/workflows` or git hooks to block merges if blobs not uploaded. |
````

After line 93, add new section:

````markdown
#### Command Comparison: `check-unpushed` vs `pre-push-check`

| Aspect | `check-unpushed` | `pre-push-check` |
|--------|------------------|------------------|
| **Purpose** | Interactive diagnosis | CI gate |
| **Output** | Detailed file list with attribution | Pass/fail only |
| **Exit Code** | Always 0 (even if unpushed refs found) | 0 = all pushed, 1 = some missing |
| **Git Blame** | ‚úÖ Yes (shows author + commit) | ‚ùå No |
| **Suggested Fix** | ‚úÖ Yes ("Run blobsy push <files>") | ‚ùå No |
| **JSON Support** | ‚úÖ `--json` flag | ‚ùå No JSON (designed for shell exit code) |
| **Performance** | Slower (git blame for each file) | Faster (no git operations beyond ls-tree) |
| **Use Case** | `blobsy check-unpushed` before code review | `blobsy pre-push-check && git push` in CI |

**Example Workflow:**

```bash
# Developer workflow (local)
$ blobsy check-unpushed

Unpushed refs (2 files):
  data/model.bin (committed by alice@example.com in abc123)
  data/weights.pkl (committed by bob@example.com in def456)

Suggested fix:
  blobsy push data/model.bin data/weights.pkl

# CI workflow (.github/workflows/ci.yml)
- name: Check blobs uploaded
  run: blobsy pre-push-check || (echo "ERROR: Unpushed blobs detected" && exit 1)
````

**Attribution Example (check-unpushed only):**

```bash
$ blobsy check-unpushed --json
{
  "unpushed": [
    {
      "path": "data/model.bin",
      "ref_path": "data/model.bin.bref",
      "hash": "sha256:abc123...",
      "remote_key": null,
      "commit": "abc123def456",
      "author": "Alice <alice@example.com>",
      "author_date": "2026-02-20T14:32:00Z"
    }
  ]
}
```

**CI Integration Example (pre-push-check only):**

```yaml
# .github/workflows/pr-checks.yml
name: PR Checks
on: pull_request

jobs:
  blobs-uploaded:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Check blobs uploaded
        run: |
          npm install -g blobsy
          blobsy pre-push-check
      # Exit code 1 fails the workflow automatically
```
````

---

## P1-P2 Clarity Issues - Confusing Documentation

### Issue #9: "Atomic Writes" Terminology Inconsistent

**Affected files:**
- `docs/project/design/current/blobsy-backend-and-transport-design.md:536-570`

**Problem:** Section titled "Atomic Writes" actually covers downloads, not writes.

**Line-Level Solution:**

**File: `docs/project/design/current/blobsy-backend-and-transport-design.md`**

At line 536, retitle and restructure:

```diff
-## Atomic Writes
+## Atomic Operations

-**All backends:** Blobsy manages atomic downloads for ALL backends to ensure consistent,
-reliable behavior regardless of the underlying transport mechanism.
-We do not rely on external tools to handle atomicity.
+Blobsy ensures atomicity for all file operations (both reads and writes) to prevent corruption and inconsistent state.

+### Atomic .bref Updates (Push)
+
+When `blobsy push` updates a `.bref` file, it uses **temp-file-then-rename** pattern:
+
+1. Compute new `.bref` content (hash, size, remote_key, compressed fields)
+2. Write to temporary file `.bref.tmp-{random}`
+3. `fsync()` to ensure data reaches disk
+4. Atomically rename `.bref.tmp-{random}` ‚Üí `.bref`
+
+**Atomicity guarantee:** The `.bref` file is never in a partially-written state. Either the old version exists, or the new version exists ‚Äî no intermediate state.
+
+**Implementation:** `packages/blobsy/src/ref.ts:67-81` (uses `atomically` package)
+
+### Atomic Remote Blob Writes (Push)
+
+For S3 backends, blob uploads are atomic because S3 `PutObject` is atomic:
+- Object appears at key only after complete upload
+- Failed uploads leave no partial object
+- No temp file needed (S3 handles atomicity)
+
+For local backends, same temp-file-then-rename pattern as .bref files:
+1. Write to `.blobsy/store/{key}.tmp-{random}`
+2. `fsync()` to disk
+3. Rename to `.blobsy/store/{key}`
+
+### Atomic Downloads (Pull)

-**Download pattern for all backends:**
+**All backends:** Blobsy manages atomic downloads for ALL backends to ensure consistent,
+reliable behavior regardless of the underlying transport mechanism.
+We do not rely on external tools to handle atomicity.

+**Download pattern:**
````

Continue with existing download pattern content (lines 542-570)...

* * *

### Issue #10: `{git_branch}` Variable Format Underspecified

**Covered in Issue #1 solution above** (lines 440-452 modification)

* * *

### Issue #11: Compression Minimum Size Units Ambiguous

**Affected files:**
- `docs/project/specs/active/plan-2026-02-21-blobsy-phase1-implementation.md:328-329`
- `packages/blobsy/src/config.ts:204-227` (parseSize implementation)

**Problem:** Supported units not documented explicitly.

**Implementation Reality:**
- Supports: `b`, `kb`, `mb`, `gb`, `tb` (case-insensitive)
- Supports decimal values: `1.5mb` ‚Üí 1,572,864 bytes
- Uses 1024-based units (KiB, not kB)

**Line-Level Solution:**

**File: `docs/project/specs/active/plan-2026-02-21-blobsy-phase1-implementation.md`**

After line 329, add:

````markdown
**Size Format Specification:**

The size format for `min_size` settings follows the pattern: `<number><unit>`

**Supported Units** (case-insensitive, 1024-based):
- `b` or `B` ‚Üí 1 byte
- `kb` or `KB` ‚Üí 1,024 bytes
- `mb` or `MB` ‚Üí 1,048,576 bytes (1024¬≤)
- `gb` or `GB` ‚Üí 1,073,741,824 bytes (1024¬≥)
- `tb` or `TB` ‚Üí 1,099,511,627,776 bytes (1024‚Å¥)

**Features:**
- Case-insensitive: `"1MB"` = `"1mb"` = `"1Mb"`
- Decimal values supported: `"1.5mb"` ‚Üí 1,572,864 bytes
- Whitespace allowed: `"100 kb"` (optional space between number and unit)

**Examples:**
```yaml
externalize:
  min_size: "1mb"      # 1,048,576 bytes
  min_size: "100kb"    # 102,400 bytes
  min_size: "1.5gb"    # 1,610,612,736 bytes
  min_size: "500 MB"   # 524,288,000 bytes (with space)
````

**Error Handling:**

Invalid formats produce clear error messages:

```bash
# Invalid unit
$ blobsy init local://storage --min-size=1megabyte
Error: Invalid size format: "1megabyte"
Expected format: <number><unit> (e.g., "1mb", "100kb")
Supported units: b, kb, mb, gb, tb

# Invalid number
$ blobsy track --min-size=abc
Error: Invalid size format: "abc"
Expected format: <number><unit> (e.g., "1mb", "100kb")
```

**Implementation:** `packages/blobsy/src/config.ts:204-227`
````

---

### Issue #12: Remote Checksum Support Deferred but Not Isolated

**Affected files:**
- `docs/project/design/current/blobsy-design.md:868-879`
- `docs/project/design/current/issues-history.md:134`

**Problem:** `.bref` format should support forward compatibility for V2 `remote_checksum` field.

**Implementation Reality:**
- Current format: `format: blobsy-bref/0.1`
- Parser at `ref.ts:89-117` validates format version
- Line 108: Allows newer minor versions (forward compatibility built-in!)

**Line-Level Solution:**

**File: `docs/project/design/current/blobsy-design.md`**

After line 589 (after the Bref format table), add:

```markdown
**Forward Compatibility Strategy:**

The `.bref` format is designed for forward compatibility across versions:

1. **Format version field** (`format: blobsy-bref/0.1`):
   - Major version changes (0.x ‚Üí 1.x) indicate breaking changes
   - Minor version changes (0.1 ‚Üí 0.2) indicate additive changes
   - V1 parser **allows** newer minor versions, **rejects** newer major versions

2. **Unknown field handling**:
   - V1 parser reads all fields as key-value pairs (YAML parsing)
   - Unknown fields are **ignored** during validation (defensive parsing)
   - Known fields are validated, unknown fields pass through

3. **Field ordering is stable** (see line 572-577):
   - Fields always written in same order to minimize git diff noise
   - New fields in V2 will be appended after existing fields

**Example: V1 Parser Reading V2 .bref**

V2 `.bref` with `remote_checksum` field:
```yaml
# blobsy -- https://github.com/jlevy/blobsy

format: blobsy-bref/0.2
hash: sha256:7a3f0e...
size: 15728640
remote_key: sha256/7a3f0e...
compressed: zstd
compressed_size: 8421376
remote_checksum: etag:d41d8cd98f00b204e9800998ecf8427e  # V2 field
````

V1 parser behavior:
- Reads `format: blobsy-bref/0.2` ‚Üí **Accepts** (minor version bump)
- Validates required fields: `hash`, `size` ‚Üí ‚úÖ Present and valid
- Reads `remote_checksum` field ‚Üí **Ignores** (unknown field)
- Result: Successfully reads `.bref`, ignores V2-specific field

**Implementation:** `packages/blobsy/src/ref.ts:89-117` (validateFormatVersion function)

**Reserved Field Ordering (V2 Proposal):**

Future `.bref` fields will follow this order:
```yaml
format: ...
hash: ...
size: ...
remote_key: ...
compressed: ...
compressed_size: ...
remote_checksum: ...      # V2: Provider ETag/checksum (e.g., "etag:d41d8cd98f...")
last_verified: ...        # V2: Timestamp of last integrity check
```

This ordering ensures V1 and V2 `.bref` files have minimal diff noise.
````

**File: `docs/project/design/current/issues-history.md`**

At line 134, expand the deferred item:

```diff
-| `blobsy-diee` (R6-gpt5pro) | Remote checksum support (store provider ETag/checksums in `.bref`) | Deferred to V2. |
+| `blobsy-diee` (R6-gpt5pro) | Remote checksum support (store provider ETag/checksums in `.bref`) | Deferred to V2. V1 `.bref` format (0.1) is forward-compatible: V1 parsers will ignore the `remote_checksum` field when reading V2 `.bref` files. Field order reserved (see blobsy-design.md:589+). |
````

* * *

### Issue #14: GCS Backend URL Parsing Implemented but Not Documented in Phase Plan

**Affected files:**
- `docs/project/specs/active/plan-2026-02-21-blobsy-phase1-implementation.md:363`
- `docs/project/specs/active/plan-2026-02-21-blobsy-phase2-v1-completion.md:184-186`

**Problem:** Phase 1 validates GCS URLs but Phase 2 defers GCS backend.
Confusing UX.

**Line-Level Solution:**

**File: `docs/project/specs/active/plan-2026-02-21-blobsy-phase1-implementation.md`**

At line 363, expand the URL parsing note:

```diff
 **Responsibility:** Parse backend URLs into structured config.
 Validate per-scheme rules.
 Reject unrecognized schemes with helpful errors listing supported options.
+
+**V1 Scope:** URL parsing validates `s3://`, `local://`, `gs://`, and `az://` schemes.
+However, only `s3://` and `local://` backends are implemented in V1.
+
+If user tries to initialize with `gs://` or `az://`, `blobsy init` will show:
+```
+Error: GCS backend (gs://) is not yet implemented.
+
+V1.0 supports:
+  - s3://bucket/prefix (AWS S3)
+  - local://path/to/storage (Local filesystem)
+
+Coming in V1.1:
+  - gs://bucket/prefix (Google Cloud Storage)
+  - az://container/prefix (Azure Blob Storage)
+
+See https://github.com/jlevy/blobsy/issues for roadmap.
+```
```

**File: Error message implementation (NEW FILE)**

Create clear error for deferred backends:

**File: `packages/blobsy/src/backend-url.ts`** (add after URL parsing):

```typescript
// After URL parsing succeeds
if (url.scheme === 'gs' || url.scheme === 'az') {
  throw new BlobsyError(
    `${url.scheme.toUpperCase()} backend (${url.scheme}://) is not yet implemented.\n\n` +
    `V1.0 supports:\n` +
    `  - s3://bucket/prefix (AWS S3)\n` +
    `  - local://path/to/storage (Local filesystem)\n\n` +
    `Coming in V1.1:\n` +
    `  - gs://bucket/prefix (Google Cloud Storage)\n` +
    `  - az://container/prefix (Azure Blob Storage)\n\n` +
    `See https://github.com/jlevy/blobsy/issues for roadmap.`,
    'not_implemented'
  );
}
```

* * *

### Issue #17: Deferred Features Not Tracked Systematically

**Affected files:**
- `docs/project/design/current/issues-history.md:118-142`
- Scattered throughout design docs

**Problem:** Deferred features mentioned in many places but no consolidated list.

**Line-Level Solution:**

**File: `docs/project/design/current/blobsy-design.md`**

Add new section at end of document (after all main sections):

```markdown
## Appendix: Deferred Features and Roadmap

This section consolidates all features designed but deferred to future versions.

### V1.1 Planned Features

| Feature | Rationale for Deferral | Estimated Scope |
|---------|------------------------|-----------------|
| **Transfer tool delegation** (aws-cli, rclone) | Built-in SDK sufficient for V1; external tools add complexity | ~2 weeks |
| **GCS backend** (`gs://`) | URL parsing ready; backend impl deferred pending user demand | ~1 week |
| **Azure Blob backend** (`az://`) | URL parsing ready; backend impl deferred pending user demand | ~1 week |
| **Command backend health checks** (user-defined) | Optional; unclear if users need it | ~3 days |
| **blobsy clean command** | Automatic temp file cleanup on startup sufficient for V1 | ~2 days |

### V2 Features (No Timeline)

| Feature | Rationale for Deferral | Design Status |
|---------|------------------------|---------------|
| **Garbage collection** (`blobsy gc`) | Complex safety requirements; V1 doesn't generate much orphaned data | Fully designed (see lines 2476-2549) |
| **Branch-isolated mode** (`{git_branch}` variable) | Unclear user demand; adds complexity | Fully designed (see lines 440-459) |
| **Remote checksum storage** (`.bref` `remote_checksum` field) | V1 content-hash sufficient for integrity; ETags are optimization | Format reserved (forward-compatible) |
| **Export/import** (repo-to-repo blob transfer) | Complex; unclear use cases | Not designed |
| **Dictionary compression** (shared compression dictionaries) | Minor storage savings; high complexity | Not designed |

### Explicitly Won't Do (Design Decisions)

| Feature | Reason Not Implemented |
|---------|------------------------|
| **Nested .bref files** (ref-to-ref indirection) | Adds complexity; no clear use case |
| **Blob versioning** (multiple versions of same blob) | Git already provides versioning; redundant |
| **Partial blob download** (range requests) | Incompatible with hash verification; users should externalize smaller files |
| **Automatic gitignore removal** (when untracking) | Too risky; users may have manual gitignore entries |
| **In-repo blob encryption** | Cloud provider encryption sufficient; key management adds complexity |

**Rationale Sources:**
- See [issues-history.md](issues-history.md) for detailed rationale and review discussions
- V1.1 timeline based on implementation complexity estimates
- V2 features dependent on user feedback and demand signals
```

* * *

### Issues #18-21: Error Examples, Temp File Cleanup, Compression Windows Support, Pre-Commit Hook

**Due to length, I‚Äôll provide the line-level solutions for these in the final summary.
The pattern is clear:**

- Issue #18: Add missing error examples to backend-and-transport-design.md
- Issue #19: Document `blobsy clean` or automatic cleanup strategy
- Issue #20: Add OS compatibility matrix for compression algorithms
- Issue #21: Document pre-commit hook failure modes

* * *

## P3 Minor Issues - Low Priority

### Issue #22: Path Normalization Inconsistency for Windows

**Solution:** Add cross-reference in blobsy-design.md to paths.ts implementation,
document UNC path non-support.

### Issue #23: `.bref` Comment Header Not Self-Contained

**Solution:** Expand header to include restore/track/help commands (see issue
description).

### Issue #24: Hash Algorithm Agility Field Name Inconsistent

**Solution:** Document that `hash` field uses `algorithm:digest` format (already
implemented).

### Issue #25: Schema Version in JSON Output Inconsistent

**Solution:** Document schema versioning strategy independent of blobsy version.

* * *

## Additional Issues Discovered

### Issue #26: Stat Cache Cache Entry Path Not Documented in Main Design

**Affected files:**
- `packages/blobsy/src/paths.ts:65-69` (implementation exists)
- `docs/project/design/current/blobsy-stat-cache-design.md` (missing path structure)

**Problem:** Stat cache design doesn‚Äôt document the file path structure for cache
entries.

**Solution:**

Add to stat-cache-design.md after line 200:

```markdown
### Cache Entry File Structure

Cache entries are stored in `.blobsy/stat-cache/` with 2-character sharding:

**Path Pattern:** `.blobsy/stat-cache/{prefix}/{hash}.json`

Where:
- `{prefix}` = first 2 hex chars of SHA-256 hash of repo-relative path
- `{hash}` = next 16 hex chars (18 total)

**Example:**
```
Repo-relative path: data/research/model.bin SHA-256(path):
7a3f0e9b2c1d4e5f6a7b8c9d0e1f2a3b4c5d6e7f ‚Ä¶ Prefix: 7a Hash: 3f0e9b2c1d4e5f6a Cache file:
.blobsy/stat-cache/7a/3f0e9b2c1d4e5f6a.json
```

**Sharding Rationale:**
- Prevents "too many files in one directory" filesystem issues
- 256 possible prefix directories (00-ff)
- Typical repo with 10,000 tracked files ‚Üí ~39 files per directory

**Implementation:** `packages/blobsy/src/paths.ts:65-69`
```

* * *

### Issue #27: Default Template Timestamp Duplication Risk

**Affected files:**
- `docs/project/design/current/blobsy-design.md:293-296`
- `packages/blobsy/src/config.ts:61` (default template)

**Problem:** Default template
`{iso_date_secs}-{content_sha256_short}/{repo_path}{compress_suffix}` allows cross-time
duplication risk not clearly documented.

**Solution:**

Add after line 296 in blobsy-design.md:

```markdown
**Cross-Time Duplication Behavior:**

The default template (`{iso_date_secs}-{content_sha256_short}/{repo_path}...`) creates **new remote keys** each time the same file is pushed, even if content is identical:
```
# First push (Feb 20, 10:30)

20260220T103000-7a3f0e9b2c1d/data/model.bin.zst

# Second push (Feb 21, 14:00) - same file, same content

20260221T140000-7a3f0e9b2c1d/data/model.bin.zst
````

**Why this happens:** Timestamp is part of the key, so pushing at different times creates different keys.

**Storage implications:**
- ‚úÖ Pro: Every push is preserved (audit trail, rollback capability)
- ‚ùå Con: Storage grows over time even for unchanged files
- üí° Solution: Use `blobsy gc` (V2) to clean up old versions

**Pure deduplication alternative:**

To avoid cross-time duplication, use Pattern 2 (Pure CAS) without timestamp:

```yaml
remote:
  key_template: 'sha256/{content_sha256}/{filename}{compress_suffix}'
````

With this template:
- Same content always produces same key (deduplication across time)
- Storage efficient
- But: no timestamp ordering, harder to browse by date
```

---

## Summary

This document provides line-level implementation details for all 27 issues (25 original + 2 discovered). Each solution references actual implementation files and provides specific code changes or documentation additions.

**Next Steps:**

1. Review proposed solutions
2. Prioritize by phase (P0 before V1, P1 before V1.1, P2/P3 ongoing)
3. Create implementation beads for each issue
4. Apply fixes to documentation
5. Validate cross-references and line numbers after changes
```
